{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discretizing Individual GeoLife Trajectory 1.3 sample data into a spatial grid\n",
    "\n",
    "*Part of the COVID19risk project*  \n",
    "*http://covid19risk.com/*  \n",
    "*2020-03-04*  \n",
    "\n",
    "*Copyright (C) 2020 Mikhail Voloshin, Mighty Data Inc.*  \n",
    "*All rights reserved.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this Notebook is to convert the sample GeoLife trajectory data from Microsoft (https://www.microsoft.com/en-us/download/details.aspx?id=52367) into a form that can be marshalled to a browser for purposes of being rendered client-side as a heatmap that can be navigated across space and time.\n",
    "\n",
    "The GeoLife data is hundreds of megabytes ZIPped, and over 1.5 GB expanded into CSV-based \"trajectory\" files. This is far too big and too detailed to be usable by a client.\n",
    "\n",
    "As such, the purpose of this Notebook is to simplify each individual trajectory record for easy network transmission.\n",
    "\n",
    "This Notebook discretizes individual trajectories into a spatial grid, but not a temporal one. It does, however, \"collapse\" temporal information -- that is, when an indivudal is in the same cell for multiple time ticks, it will only export the time of the individual's entry into the cell, and will assume that the individual is still in that same cell until further notified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "# The number of kilometers covered by each grid cell, in both the latitude and longitude direction.\n",
    "# Discretization is zeroed on the equator and prime meridian for latitude and longitude respectively.\n",
    "# For now, the number of kilometers per degree is fixed at a conversion rate optimized for 40oN -100oW,\n",
    "# which lies in northern Kansas near the geospatial center of the US. Future versions of this\n",
    "# script will employ an algorithm that takes the Earth's curvature into account. For now, this will lead\n",
    "# to a slight illusory increase in data points per cell (i.e. deceptively \"hotter\" cells) near\n",
    "# the equator, and an illusory decrease in data points per cell (i.e. deceptively \"colder\" cells)\n",
    "# near the poles. The distortion near the poles will be significant, but because those are far from\n",
    "# human population centers this should be acceptable.\n",
    "GRID_SPATIAL_KM = 1\n",
    "\n",
    "# The number of days for each time step into which to discretize the data.\n",
    "# Discretization is zeroed on the Unix epoch.\n",
    "GRID_TEMPORAL_DAYS = 7\n",
    "\n",
    "# Path to the unzipped Geolife data folder.\n",
    "DATA_DIR = \"../../../../data/proof-of-concept/Geolife Trajectories 1.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for trajectory files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. 182 trajectories found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    raise ValueError(DATA_DIR + \" doesn't appear to be a directory that exists on this filesystem.\")\n",
    "if not os.path.isdir(DATA_DIR+'/Data'):\n",
    "    raise ValueError(DATA_DIR + \" doesn't appear to be the unzipped Geolife dataset. It doesn't contain a /Data subdirectory.\")\n",
    "\n",
    "# A trajectory folder path is any subfolder of the Data directory that has a Trajectory subfolder.\n",
    "trajectory_folder_paths = [f.path for f in os.scandir(DATA_DIR+'/Data') if f.is_dir() and os.path.isdir(f.path+'/Trajectory')]\n",
    "\n",
    "print(f'Success. {len(trajectory_folder_paths)} trajectories found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precompute some values that will be useful to us during the computation\n",
    "\n",
    "Spatial grid degrees were computed with the help of https://andrew.hedges.name/experiments/haversine/. Future versions of this script should use trigonometry to discretize by traversing a longitudinal line in intervals of *GRID_SPATIAL_KM* km steps from the equator, and then using the Earth's cross-section at that latitude to walk by *GRID_SPATIAL_KM* km steps from the prime meridian. It's not hard, but a little too tedious to go through the trouble of writing said function for this proof-of-concept stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELLSIZE_SECONDS = GRID_TEMPORAL_DAYS * 24 * 60 * 60\n",
    "\n",
    "CELLSIZE_DEGREES_LAT = GRID_SPATIAL_KM * 0.00899\n",
    "CELLSIZE_DEGREES_LONG = GRID_SPATIAL_KM * 0.01174\n",
    "CELLSIZE_DEGREES_PRECISION = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "MICROSOFT_EPOCH_START = time.mktime(datetime.datetime.strptime('1899-12-30', '%Y-%m-%d').timetuple())\n",
    "\n",
    "def convert_microsoft_epoch_to_unixtime(dayscount):\n",
    "    # Microsoft Research encoded this dataset to include a field\n",
    "    # that contains the number of days that have elapsed since\n",
    "    # Dec 30 (not 31), 1899. No word on whether this is midnight\n",
    "    # at the *beginning* or *end* of said date, but we can validate\n",
    "    # against the other date and time columns to make sure we\n",
    "    # got it right (which we did).\n",
    "\n",
    "    secondscount = dayscount * 24 * 60 * 60\n",
    "    retval = MICROSOFT_EPOCH_START + secondscount\n",
    "    return int(retval)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlong_fstring_part = f'{{:.{CELLSIZE_DEGREES_PRECISION}f}}'\n",
    "latlong_fstring = f'{latlong_fstring_part},{latlong_fstring_part}'\n",
    "\n",
    "def determine_spatial_grid_cell(df):\n",
    "    df['unixtime'] = df['daysSinceMicrosoftEpoch'].apply(convert_microsoft_epoch_to_unixtime)    \n",
    "    \n",
    "    # We're using int as a de facto math.floor function\n",
    "    df['cell_latitude'] = (df['latitude'] / CELLSIZE_DEGREES_LAT).apply(int) * CELLSIZE_DEGREES_LAT\n",
    "    df['cell_longitude'] = (df['longitude'] / CELLSIZE_DEGREES_LONG).apply(int) * CELLSIZE_DEGREES_LONG\n",
    "\n",
    "    df['cell_key_spatial'] = df.apply(lambda x: latlong_fstring.format(x['cell_latitude'], x['cell_longitude']), axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate our data structures\n",
    "This script should take about 20 minutes to run on a 2.8 Ghz Lenovo laptop with 16 GB RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2020-03-13 01:45:57.836947\n",
      "Processing Trajectory ID: 000\n",
      "171 trajectory plots found.\n",
      "...........................................................................................................................................................................\n",
      "Trajectory ID 000 done.\n",
      "\n",
      "Processing Trajectory ID: 001\n",
      "71 trajectory plots found.\n",
      "........................................"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Started at {datetime.datetime.now()}')\n",
    "\n",
    "import math\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# The column meanings come from the User Guide PDF that comes with the Geolife dataset.\n",
    "GEOLIFE_COLUMNS = [\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'reserved0',\n",
    "    'altitude',\n",
    "    'daysSinceMicrosoftEpoch',\n",
    "    'date',\n",
    "    'time'    \n",
    "]\n",
    "\n",
    "trajectories_time_in_cell = {}\n",
    "\n",
    "\n",
    "for traj_path in trajectory_folder_paths:\n",
    "    traj_id = traj_path.split('/')[-1]\n",
    "    print(f'Processing Trajectory ID: {traj_id}')\n",
    "\n",
    "    cells_hit_by_this_traj = set()\n",
    "    \n",
    "    traj_filenames = [f.path for f in os.scandir(traj_path+'/Trajectory') if f.is_file() and f.path.endswith('.plt')]\n",
    "    print(f'{len(traj_filenames)} trajectory plots found.')\n",
    "    \n",
    "    trajdf = None\n",
    "    for traj_filename in traj_filenames:\n",
    "        print('.', end='')\n",
    "        df = pd.read_csv(traj_filename, skiprows=6, names=GEOLIFE_COLUMNS)\n",
    "        determine_spatial_grid_cell(df)\n",
    "        # print(f'Read {traj_filename} into a dataframe')\n",
    "        \n",
    "        trimdf = df[['unixtime', 'cell_latitude', 'cell_longitude', 'cell_key_spatial']]\n",
    "        if trajdf is None:\n",
    "            trajdf = trimdf\n",
    "        else:\n",
    "            trajdf = trajdf.append(trimdf)\n",
    "\n",
    "    trajdf = trajdf.sort_values(by='unixtime')\n",
    "    \n",
    "    # Select only the cells that represent a change in the traveler's position.\n",
    "    # Without such a change, we can assume that the traveler is stationary.\n",
    "    trajdf['entered_cell'] = trajdf['cell_key_spatial'] != trajdf['cell_key_spatial'].shift()\n",
    "    \n",
    "    # A gap of more than an hour indicates that the user has gone offline.\n",
    "    trajdf['gone_offline'] = trajdf['unixtime'].shift(-1).isna() | ((trajdf['unixtime'].shift(-1) - trajdf['unixtime']) > (60 * 60))\n",
    "\n",
    "    trajdf_enterexits = trajdf[trajdf['entered_cell'] | trajdf['gone_offline']].copy()\n",
    "    trajdf_enterexits['unixtime_end'] = trajdf_enterexits['unixtime'].shift(-1)\n",
    "    trajdf_enterexits = trajdf_enterexits[:-1].copy()\n",
    "    trajdf_enterexits['unixtime_end'] = trajdf_enterexits['unixtime_end'].astype('int64')\n",
    "    \n",
    "    trajdf_enterexits['cell_lat_fixedpt'] = (trajdf_enterexits['cell_latitude'] * math.pow(10, CELLSIZE_DEGREES_PRECISION)).astype('int64')\n",
    "    trajdf_enterexits['cell_long_fixedpt'] = (trajdf_enterexits['cell_longitude'] * math.pow(10, CELLSIZE_DEGREES_PRECISION)).astype('int64')\n",
    "        \n",
    "    trajdf_min = trajdf_enterexits.loc[:, ['unixtime', 'unixtime_end', 'cell_lat_fixedpt', 'cell_long_fixedpt']]\n",
    "\n",
    "    # It's a little silly that the most efficient way to turn a pandas dataframe\n",
    "    # into a list of lists is to go through json, but it works.\n",
    "    trajectories_time_in_cell[traj_id] = json.loads(trajdf_min.to_json(orient='values'))\n",
    "            \n",
    "    print(f'\\nTrajectory ID {traj_id} done.\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim garbage time slots\n",
    "There appear to be a small number of errors in the timestamps of the Geolife data. As such, throw out any data that occurs before there are at least 3 active users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_with_starttime = [[traj_id, trajectory[0][0]] for traj_id, trajectory in trajectories_time_in_cell.items()]\n",
    "traj_with_starttime.sort(key = lambda x: x[1])\n",
    "\n",
    "earliest_acceptable_time = traj_with_starttime[2][1]\n",
    "print(f'Filtering out all records with a start time before {earliest_acceptable_time}')\n",
    "\n",
    "def trajectory_filtered(trajectory):\n",
    "    return [trecord for trecord in trajectory if trecord[0]>=earliest_acceptable_time]\n",
    "\n",
    "trajectories_time_in_cell = {\n",
    "    traj_id:trajectory_filtered(trajectory) for traj_id, trajectory in trajectories_time_in_cell.items()\n",
    "}\n",
    "\n",
    "traj_with_starttime = [[traj_id, trajectory[0][0]] for traj_id, trajectory in trajectories_time_in_cell.items()]\n",
    "traj_with_starttime.sort(key = lambda x: x[1])\n",
    "traj_with_starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Earliest time in recordset: {traj_with_starttime[0][1]}')\n",
    "print(f'  Latest time in recordset: {traj_with_starttime[-1][1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count how many grid cells we're using\n",
    "For sake of reference, count how many cells our data set covers. This might be useful for the client to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_used = set()\n",
    "\n",
    "# We've shaved off our cell key, but we can reconstruct something just as unique.\n",
    "# Remember we're in the integer domain, so some things are easier now.\n",
    "for trajectory in trajectories_time_in_cell.values():\n",
    "    for trecord in trajectory:\n",
    "        celldesignator = f'{trecord[1:]}'\n",
    "        all_cells_used.add(celldesignator)\n",
    "\n",
    "len(all_cells_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output\n",
    "Here's what we've been waiting for! Save our output, along with the parameters we used for creating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "# Record the grid parameters.\n",
    "results['gridparams'] = {\n",
    "    'spatial-cell-size-km': GRID_SPATIAL_KM,\n",
    "    'fixed-point-precision': CELLSIZE_DEGREES_PRECISION,\n",
    "}\n",
    "\n",
    "results['ranges'] = {\n",
    "    'num-cells': len(all_cells_used),\n",
    "    'time-start': traj_with_starttime[0][1],\n",
    "    'time-end': traj_with_starttime[-1][1]\n",
    "}\n",
    "\n",
    "# And of course, the trajectories!\n",
    "results['trajectories'] = trajectories_time_in_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('trajectories_in_spatial_grid.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
